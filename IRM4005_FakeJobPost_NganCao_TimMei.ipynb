# Fake Job Postings Detection using PyTorch
# Ngan Cao
# Tim Mei 101268588

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import re
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import numpy as np

print("Fake Job Postings Detection")

df = pd.read_csv('fake_job_postings.csv')

print(f"Total job posts: {len(df)}")
print(f"Fake jobs: {df['fraudulent'].sum()} ({df['fraudulent'].mean()*100:.1f}%)")

# Combine text fields
df['text'] = (
    df['title'].fillna('') + ' ' +
    df['description'].fillna('') + ' ' +
    df['requirements'].fillna('')
)

df = df[df['text'].str.strip() != ''].reset_index(drop=True)
print(f"Valid job posts after cleaning: {len(df)}")

# Dataset class
class JobDataset(Dataset):
    
    def __init__(self, texts, labels, vocab=None, max_length=150):
        self.texts = texts
        self.labels = labels
        self.max_length = max_length
        
        if vocab is None:
            self.vocab = self.build_vocab(texts)
        else:
            self.vocab = vocab

    def tokenize(self, text):
        # Adapted from Abbas Akkasi's sample code (2025)
        text = text.lower()
        text = re.sub(r'[^a-zA-Z\s]', '', text)
        return text.split()
    
    def build_vocab(self, texts, min_freq=2):
        # Adapted from Abbas Akkasi's sample code (2025)
        counter = Counter()
        for text in texts:
            counter.update(self.tokenize(text))
        
        vocab = {'<PAD>': 0, '<UNK>': 1}
        for word, count in counter.most_common(5000):
            if count >= min_freq:
                vocab[word] = len(vocab)
        return vocab
    
    def text_to_indices(self, text):
        # Adapted from Abbas Akkasi's sample code (2025)
        tokens = self.tokenize(text)
        indices = [self.vocab.get(t, 1) for t in tokens[:self.max_length]]
        indices.extend([0] * (self.max_length - len(indices)))
        return indices
    
    def __len__(self):
        # Adapted from Abbas Akkasi's sample code (2025)
        return len(self.texts)
    
    def __getitem__(self, idx):
        # Adapted from Abbas Akkasi's sample code (2025)
        return (
            torch.tensor(self.text_to_indices(self.texts[idx])),
            torch.tensor(self.labels[idx], dtype=torch.float)
        )

# Training and split 
texts = df['text'].tolist()
labels = df['fraudulent'].tolist()

train_texts, test_texts, train_labels, test_labels = train_test_split(
    texts, labels, test_size=0.2, random_state=42, stratify=labels
)

train_dataset = JobDataset(train_texts, train_labels)
test_dataset = JobDataset(test_texts, test_labels, vocab=train_dataset.vocab)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

print(f"\nTraining samples: {len(train_dataset)}")
print(f"Test samples: {len(test_dataset)}")
print(f"Vocabulary size: {len(train_dataset.vocab)}")


class FakeJobDetector(nn.Module):
    # LSTM-based model for fake job posting detection
    def __init__(self, vocab_size, embedding_dim=100, hidden_dim=128):
        # Adapted from Abbas Akkasi's sample code (2025)
        super(FakeJobDetector, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)
        self.lstm = nn.LSTM(
            embedding_dim, hidden_dim, batch_first=True, bidirectional=True
        )
        self.dropout = nn.Dropout(0.3)
        self.fc = nn.Linear(hidden_dim * 2, 1)
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        # Adapted from Abbas Akkasi's sample code (2025)
        embedded = self.embedding(x)
        _, (hidden, _) = self.lstm(embedded)
        hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)
        output = self.fc(self.dropout(hidden))
        return self.sigmoid(output).squeeze()

# Training function: Adapted from Abbas Akkasi's sample code (2025)
def train_model(model, train_loader, test_loader, epochs=10, lr=0.001):
    # Train the model and evaluate on test set
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    print(f"\nTraining on: {device}")
    
    criterion = nn.BCELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    
    print(f"\nStarting training for {epochs} epochs\n")
    
    # Lists to store metrics for plotting
    train_losses = []
    train_accuracies = []
    test_accuracies = []
    
    for epoch in range(epochs):
        # Training phase - Adapted from Abbas Akkasi's sample code (2025)
        model.train()
        total_loss = 0
        train_correct = 0
        train_total = 0
        
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            predicted = (outputs > 0.5).float()
            train_total += labels.size(0)
            train_correct += (predicted == labels).sum().item()
        
        train_accuracy = 100 * train_correct / train_total
        avg_loss = total_loss / len(train_loader)
        
        # Evaluation phase - Adapted from Abbas Akkasi's sample code (2025)
        model.eval()
        test_correct = 0
        test_total = 0
        
        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                predicted = (outputs > 0.5).float()
                test_total += labels.size(0)
                test_correct += (predicted == labels).sum().item()
        
        test_accuracy = 100 * test_correct / test_total
        
        # Store metrics
        train_losses.append(avg_loss)
        train_accuracies.append(train_accuracy)
        test_accuracies.append(test_accuracy)
        
        print(f"Epoch [{epoch+1:2d}/{epochs}] | "
              f"Loss: {avg_loss:.4f} | "
              f"Train Acc: {train_accuracy:.2f}% | "
              f"Test Acc: {test_accuracy:.2f}%")
    
    return model, train_losses, train_accuracies, test_accuracies

# Evaluation function
def evaluate_model(model, test_loader):
    # Printing metrics and evaluating the model    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    model.eval()
    
    predictions = []
    true_labels = []
    
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            preds = (outputs > 0.5).long()
            
            predictions.extend(preds.cpu().numpy())
            true_labels.extend(labels.numpy())
    
    # Calculate metrics
    precision = precision_score(true_labels, predictions)
    recall = recall_score(true_labels, predictions)
    f1 = f1_score(true_labels, predictions)
    
    print("\nEvaluation Metrics:")
    print(f"Precision: {precision:.4f} ({precision*100:.2f}%)")
    print(f"Recall:    {recall:.4f} ({recall*100:.2f}%)")
    print(f"F1-Score:  {f1:.4f} ({f1*100:.2f}%)")
    
    print("\nClassification Report:")
    print(classification_report(true_labels, predictions, 
                                target_names=['Real', 'Fake'], digits=4))
    
    # Confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    print("\nConfusion Matrix:")
    print(f"              Predicted")
    print(f"           Real    Fake")
    print(f"Real      {cm[0][0]:5d}  {cm[0][1]:5d}")
    print(f"Fake      {cm[1][0]:5d}  {cm[1][1]:5d}")
    
    return precision, recall, f1, cm

# Plotting function
def plot_training_results(train_losses, train_accuracies, test_accuracies):
    """Visualize training progress"""
    
    epochs = range(1, len(train_losses) + 1)
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
    
    # Plot 1: Training Loss
    ax1.plot(epochs, train_losses, 'b-', linewidth=2, label='Training Loss')
    ax1.set_xlabel('Epoch', fontsize=12)
    ax1.set_ylabel('Loss', fontsize=12)
    ax1.set_title('Training Loss Over Epochs', fontsize=14, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Plot 2: Accuracy Comparison
    ax2.plot(epochs, train_accuracies, 'g-', linewidth=2, label='Training Accuracy')
    ax2.plot(epochs, test_accuracies, 'r-', linewidth=2, label='Test Accuracy')
    ax2.set_xlabel('Epoch', fontsize=12)
    ax2.set_ylabel('Accuracy (%)', fontsize=12)
    ax2.set_title('Training vs Test Accuracy', fontsize=14, fontweight='bold')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('training_results.png', dpi=300, bbox_inches='tight')
    print("\nTraining plots saved as 'training_results.png'")
    plt.show()

def plot_confusion_matrix(cm):
    """Visualize confusion matrix"""
    
    fig, ax = plt.subplots(figsize=(8, 6))
    
    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    ax.figure.colorbar(im, ax=ax)
    
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           xticklabels=['Real', 'Fake'],
           yticklabels=['Real', 'Fake'],
           title='Confusion Matrix',
           ylabel='True Label',
           xlabel='Predicted Label')
    
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")
    
    # Add text annotations
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], 'd'),
                   ha="center", va="center",
                   color="white" if cm[i, j] > thresh else "black",
                   fontsize=20, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
    print("Confusion matrix saved as 'confusion_matrix.png'")
    plt.show()
